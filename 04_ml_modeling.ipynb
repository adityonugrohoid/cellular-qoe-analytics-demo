{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d08ca9",
   "metadata": {},
   "source": [
    "# ML Modeling — Predicting Page Load Time\n",
    "\n",
    "- Predicts `page_load_time_ms` using radio, device, operator, and context features.\n",
    "- Time-aware train/test split (80/20%).\n",
    "- Pipeline: scales numerics, one-hot encodes categoricals.\n",
    "- Models: Linear, Decision Tree, Random Forest, Gradient Boosting.\n",
    "- Evaluates R², RMSE, MAE; visualizes actual vs. predicted.\n",
    "- Picks best by RMSE and saves the model.\n",
    "- Surfaces feature importance for transparency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b12e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports & load\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "if os.path.exists(\"synthetic_qoe_sessions_clean.parquet\"):\n",
    "    df = pd.read_parquet(\"synthetic_qoe_sessions_clean.parquet\")\n",
    "else:\n",
    "    df = pd.read_csv(\"synthetic_qoe_sessions_clean.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "print(f\"Loaded cleaned dataset with shape: {df.shape}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature selection & preprocessing (predict page_load_time from radio+network)\n",
    "TARGET = 'page_load_time_ms'\n",
    "\n",
    "cat_features = ['device', 'operator', 'band']\n",
    "num_features = ['rsrp_dbm', 'rsrq_db', 'sinr_db', 'app_size_kb', 'rtt_ms']\n",
    "\n",
    "# Time context\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "num_features = num_features + ['hour']\n",
    "\n",
    "# Sort by time and build time-aware split (first 80% train, last 20% test)\n",
    "df_sorted = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "X = df_sorted[cat_features + num_features]\n",
    "y = df_sorted[TARGET]\n",
    "\n",
    "split_idx = int(0.8 * len(df_sorted))\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# Preprocess: numeric median impute; categorical most_frequent + OHE\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "num_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# ---- Print remarks for interpretation ----\n",
    "print(\"\\n[Feature Selection & Preprocessing — PLT model]\")\n",
    "\n",
    "# Explicit checks to avoid leakage / redundant features\n",
    "assert 'country' not in cat_features, \"Do not include 'country' — negligible signal.\"\n",
    "assert ('band' in cat_features) and ('network_type' not in cat_features), \\\n",
    "       \"Use 'band' OR 'network_type' — not both. Chose 'band'.\"\n",
    "\n",
    "print(f\"- Target: {TARGET}\")\n",
    "print(f\"- Categorical features: {cat_features}  (excluded: 'country'; chose 'band', not 'network_type')\")\n",
    "print(f\"- Numeric features: {num_features}\")\n",
    "\n",
    "# Time-aware split summary\n",
    "ts_start = df_sorted['timestamp'].iloc[0]\n",
    "ts_split = df_sorted['timestamp'].iloc[split_idx-1]\n",
    "ts_end   = df_sorted['timestamp'].iloc[-1]\n",
    "print(\"- Split: time-aware (first 80% → train, last 20% → test) to avoid temporal leakage.\")\n",
    "print(f\"  · Train window: {ts_start:%Y-%m-%d %H:%M} → {ts_split:%Y-%m-%d %H:%M}  (n={len(X_train):,})\")\n",
    "print(f\"  · Test  window: {df_sorted['timestamp'].iloc[split_idx]:%Y-%m-%d %H:%M} → {ts_end:%Y-%m-%d %H:%M}  (n={len(X_test):,})\")\n",
    "\n",
    "# Preprocessing summary\n",
    "print(\"- Preprocess:\")\n",
    "print(\"  · Numeric: SimpleImputer(strategy='median') → replaces missing values with median per column.\")\n",
    "print(\"  · Categorical: SimpleImputer(strategy='most_frequent') → replaces missing values with the most common category.\")\n",
    "print(\"  · OneHotEncoder(handle_unknown='ignore') → expands categorical variables into binary indicators.\")\n",
    "print(\"  · ColumnTransformer(remainder='drop') → only selected features pass through.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc663cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train & evaluate multiple models via pipelines\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "fitted = {}\n",
    "rows = []\n",
    "for name, est in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocess', preprocess), ('model', est)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    mse  = mean_squared_error(y_test, y_pred)\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    rows.append({\"Model\": name, \"R2\": r2, \"RMSE\": rmse, \"MAE\": mae})\n",
    "    fitted[name] = {\"pipe\": pipe, \"y_pred\": y_pred}\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(\"RMSE\")\n",
    "print(\"\\n--- Model Performance Summary (time-aware split) ---\")\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41107dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Pick best model (by RMSE), persist artefacts\n",
    "best_row = summary_df.iloc[0]\n",
    "best_name = best_row[\"Model\"]\n",
    "best_pipe = fitted[best_name][\"pipe\"]\n",
    "print(f\"Best model: {best_name}  |  RMSE={best_row['RMSE']:.4f}  R2={best_row['R2']:.3f}\")\n",
    "\n",
    "os.makedirs(\"artefacts\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "summary_df.to_csv(\"artefacts/model_metrics.csv\", index=False)\n",
    "\n",
    "model_path = f\"models/qoe_{TARGET}_best_model.joblib\"\n",
    "joblib.dump(best_pipe, model_path)\n",
    "print(f\"Saved best model → {model_path}\")\n",
    "\n",
    "# Mini model card\n",
    "card = f\"\"\"# Model Card — QoE {TARGET}\n",
    "\n",
    "**Best model:** {best_name}\n",
    "**Train/Test split:** time-ordered, first 80% train / last 20% test\n",
    "**Metrics (test):** R2={best_row['R2']:.3f}, RMSE={best_row['RMSE']:.4f}, MAE={best_row['MAE']:.4f}\n",
    "\n",
    "**Features**\n",
    "- Numerical: {', '.join(num_features)}\n",
    "- Categorical (OHE): {', '.join(cat_features)}\n",
    "\n",
    "**Notes**\n",
    "- Radio KPIs (RSRP/RSRQ/SINR) and operator/band materially explain {TARGET}.\n",
    "- Time-aware split avoids leakage from random shuffling on temporal data.\n",
    "\"\"\"\n",
    "with open(\"models/model_card.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(card)\n",
    "print(\"Wrote models/model_card.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature importance (permutation) — top 15 on test split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from typing import Any\n",
    "\n",
    "# Permutation importance permutes original input columns (pre-pipeline),\n",
    "# so the names are our original features:\n",
    "model_features = cat_features + num_features\n",
    "\n",
    "pi_result = permutation_importance(\n",
    "    best_pipe,              # Pipeline\n",
    "    X_test,                 # original feature DataFrame\n",
    "    y_test,\n",
    "    n_repeats=5,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "def _pi_get(obj: Any, key: str):\n",
    "    return getattr(obj, key, obj[key])\n",
    "\n",
    "imp_mean = _pi_get(pi_result, \"importances_mean\")\n",
    "imp_std  = _pi_get(pi_result, \"importances_std\")\n",
    "\n",
    "pi_mean = pd.Series(imp_mean, index=model_features)\n",
    "pi_std  = pd.Series(imp_std,  index=model_features)\n",
    "\n",
    "imp = (\n",
    "    pi_mean.sort_values(ascending=False)\n",
    "           .rename(\"mean_importance\")\n",
    "           .to_frame()\n",
    "           .assign(std=pi_std)\n",
    ")\n",
    "\n",
    "top = imp.head(15)\n",
    "\n",
    "# ---- Print remarks for interpretation ----\n",
    "print(\"\\n[Permutation Importance — Explanation & Interpretation]\")\n",
    "print(\"- Method: Each feature is randomly permuted (shuffled) in X_test while keeping all others fixed.\")\n",
    "print(\"  · If the model’s MSE rises significantly → the feature was important.\")\n",
    "print(\"  · If the MSE barely changes → the feature had little predictive value.\")\n",
    "print(\"- Why: Unlike model coefficients, this directly measures feature contribution to prediction accuracy.\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "top.sort_values(\"mean_importance\").plot.barh(y=\"mean_importance\", xerr=\"std\", legend=False, ax=ax)\n",
    "ax.set_title(f\"Permutation Importance (top 15) — {best_name}\")\n",
    "ax.set_xlabel(\"Importance (↑ = larger error when permuted)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ---- Print remarks for interpretation ----\n",
    "print(\"- Interpretation of bar chart:\")\n",
    "print(\"  · Features at the top: highest impact — shuffling them causes the largest rise in MSE.\")\n",
    "print(\"  · Error bars (std): variation across 5 repeats; wider bars mean less stable importance.\")\n",
    "print(\"- Practical use: Focus optimization on features with high permutation importance; low-importance features can be candidates for dropping.\")\n",
    "\n",
    "# Save importances\n",
    "os.makedirs(\"artefacts\", exist_ok=True)\n",
    "imp.to_csv(f\"artefacts/permutation_importance_{TARGET}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbad861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Diagonal plots — ALL models\n",
    "import math, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "os.makedirs(\"artefacts\", exist_ok=True)\n",
    "\n",
    "def _rmse(y_true, y_pred):\n",
    "    try:\n",
    "        return mean_squared_error(y_true, y_pred, squared=False)\n",
    "    except TypeError:\n",
    "        return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def diag_grid_all_models(y_true, fitted_dict, summary_df, target_name):\n",
    "    # Order plots by RMSE (best first)\n",
    "    model_order = summary_df.sort_values(\"RMSE\")[\"Model\"].tolist()\n",
    "    n = len(model_order)\n",
    "    cols = 2 if n > 1 else 1\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    # ---- Print remarks for interpretation ----\n",
    "    print(\"\\n[Model Prediction vs Actual Scatter — Interpretation]\")\n",
    "    print(\"- Each subplot shows predicted vs actual Page Load Time (PLT) for one model.\")\n",
    "    print(\"- The red dashed line = ideal diagonal (perfect prediction).\")\n",
    "    print(\"- Points hugging the diagonal → model predictions are close to reality.\")\n",
    "    print(\"- Wider scatter from the diagonal → larger prediction error.\")\n",
    "    print(\"- RMSE in titles gives the average magnitude of these errors (lower = better).\")\n",
    "\n",
    "    # Common axis limits across all models\n",
    "    y_min = float(min([np.min(y_true)] + [np.min(fitted_dict[m][\"y_pred\"]) for m in model_order]))\n",
    "    y_max = float(max([np.max(y_true)] + [np.max(fitted_dict[m][\"y_pred\"]) for m in model_order]))\n",
    "\n",
    "    # Shared axes to keep identical scales\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows),\n",
    "                             sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "    last_idx = -1\n",
    "    for i, m in enumerate(model_order):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        y_pred = fitted_dict[m][\"y_pred\"]\n",
    "        rmse = _rmse(y_true, y_pred)\n",
    "        ax.scatter(y_true, y_pred, alpha=0.25, s=12)\n",
    "        ax.plot([y_min, y_max], [y_min, y_max], 'r--', lw=2)\n",
    "        ax.set_title(f\"{m}   RMSE={rmse:.0f}\")\n",
    "        ax.set_xlim([y_min, y_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.label_outer()  # hide inner tick labels\n",
    "        last_idx = i\n",
    "\n",
    "    # Remove unused axes (if any)\n",
    "    for j in range(last_idx + 1, rows * cols):\n",
    "        fig.delaxes(axes[j // cols, j % cols])\n",
    "\n",
    "    # One set of common labels\n",
    "    fig.text(0.5, 0.04, f\"Actual {target_name}\", ha='center')\n",
    "    fig.text(0.04, 0.5, f\"Predicted {target_name}\", va='center', rotation='vertical')\n",
    "\n",
    "    plt.tight_layout(rect=(0.06, 0.06, 1, 1))\n",
    "    fig.savefig(\"artefacts/actual_vs_pred_all_models.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Call it\n",
    "diag_grid_all_models(y_test, fitted, summary_df, TARGET)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qoe-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
